{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1e-EtboixUBLzfIhxD4RAdfJi6iyAkdP9?usp=sharing)"
      ],
      "metadata": {
        "id": "5OzODVj0gLsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comment:\n",
        "Due to the unavailability of cloud vendor services like AWS or Azure Databricks, this script is designed to mimic a Databricks environment using PySpark in Google Colab. PySpark offers a scalable environment for handling big data, which is similar to the capabilities provided by Databricks. The primary goal here is to perform dimensionality reduction on a cinema ticket dataset. We initialize a Spark session, preprocess the data, and then apply Principal Component Analysis (PCA), a technique commonly used in Databricks for reducing data dimensions. This approach allows us to leverage the power of Spark in a local environment without needing access to cloud-based Databricks services.\n"
      ],
      "metadata": {
        "id": "P-tHqpCyUrFK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T4YCLx1RlQ5",
        "outputId": "6730b50c-fa28-4cb7-abc7-122750e7b95f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=575c271f08280cdf3586a22863e343165263e3fcea4d914620c04edf3d46e2e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "# Install PySpark\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Necessary Libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, PCA\n",
        "from pyspark.sql.types import IntegerType, DoubleType, FloatType"
      ],
      "metadata": {
        "id": "UqzPDLJ1TD1h"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"PCA_Cinema_Ticket_Sales\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "k0xNudSmTOWy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Data\n",
        "file_path = '/content/cinemaTicket_Ref.csv'  # Replace with your file path\n",
        "sdf = spark.read.csv(file_path, header=True, inferSchema=True)\n"
      ],
      "metadata": {
        "id": "_TMer1X3TWmd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the schema to confirm correct data types\n",
        "sdf.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bKpJEkOUX51",
        "outputId": "fe9bad7b-7a68-4c83-a20a-1328ea63244c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- film_code: integer (nullable = true)\n",
            " |-- cinema_code: integer (nullable = true)\n",
            " |-- total_sales: integer (nullable = true)\n",
            " |-- tickets_sold: integer (nullable = true)\n",
            " |-- tickets_out: integer (nullable = true)\n",
            " |-- show_time: integer (nullable = true)\n",
            " |-- occu_perc: double (nullable = true)\n",
            " |-- ticket_price: double (nullable = true)\n",
            " |-- ticket_use: integer (nullable = true)\n",
            " |-- capacity: double (nullable = true)\n",
            " |-- date: date (nullable = true)\n",
            " |-- month: integer (nullable = true)\n",
            " |-- quarter: integer (nullable = true)\n",
            " |-- day: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values if any\n",
        "sdf_filled = sdf_numerical.na.fill(0)"
      ],
      "metadata": {
        "id": "iWBeif3nToYO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform PCA\n",
        "# Assembling the features into a single vector\n",
        "vec_assembler = VectorAssembler(inputCols=sdf_filled.columns, outputCol=\"features\")\n",
        "sdf_assembled = vec_assembler.transform(sdf_filled)\n"
      ],
      "metadata": {
        "id": "lB5nGCDATsgY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing PCA\n",
        "pca = PCA(k=3, inputCol=\"features\", outputCol=\"pcaFeatures\")  # k is the number of dimensions\n",
        "model = pca.fit(sdf_assembled)\n",
        "sdf_pca = model.transform(sdf_assembled)"
      ],
      "metadata": {
        "id": "vlra931CTxun"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the Results\n",
        "# Selecting and displaying the PCA features\n",
        "sdf_pca.select(\"pcaFeatures\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igSpGaaDT319",
        "outputId": "71efe9f0-4d3c-4fc8-eab2-b90d8426a20b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|         pcaFeatures|\n",
            "+--------------------+\n",
            "|[-3900044.1462103...|\n",
            "|[-3360023.4913592...|\n",
            "|[-2560023.5219989...|\n",
            "|[-1200029.4885063...|\n",
            "|[-1200023.5804174...|\n",
            "|[-1050044.2718581...|\n",
            "|[-1020030.0874049...|\n",
            "|[-750044.28030764...|\n",
            "|[-750020.12150391...|\n",
            "|[-600044.28614579...|\n",
            "|[-480023.62667965...|\n",
            "|[-480035.42809373...|\n",
            "|[-400023.62525466...|\n",
            "|[-300044.30558242...|\n",
            "|[-240035.43816157...|\n",
            "|[-1.6500042804953...|\n",
            "|[-1.3950043710614...|\n",
            "|[-1.0200043873347...|\n",
            "|[-6600044.0295966...|\n",
            "|[-3360031.8720071...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explained Variance\n",
        "print(\"Explained Variance:\", model.explainedVariance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXJPF1CKT9LB",
        "outputId": "f77fd552-7ff0-4c59-f61e-3391af2a7f13"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explained Variance: [0.9999989108412257,1.0882862864747461e-06,8.251056539257937e-10]\n"
          ]
        }
      ]
    }
  ]
}